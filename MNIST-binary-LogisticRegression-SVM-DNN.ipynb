{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules for MNIST data, Logistic Regression, SVM, DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import modules\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "## MNIST Dataset\n",
    "#from keras.datasets import mnist\n",
    "\n",
    "## Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## SVM model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "## Keras for DNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MNIST data \n",
    "### Data Preparation - only 9 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import MNIST data \n",
    "b = np.load('./data/mnist.npz')\n",
    "## train and test data\n",
    "X_train, y_train, X_test, y_test = b['x_train'], b['y_train'], b['x_test'], b['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import MNIST data from Keras dataset library\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "## Train data\n",
    "# Extract all 9s and  3s\n",
    "y_train_9 = y_train[y_train == 9]\n",
    "y_train_3 = y_train[y_train == 3]\n",
    "X_train_9 = X_train[y_train == 9]\n",
    "X_train_3 = X_train[y_train == 3]\n",
    "\n",
    "## concatenate 9 and 3\n",
    "X_train2 = np.concatenate((X_train_9, X_train_3), axis=0)\n",
    "y_train2 = np.concatenate((y_train_9, y_train_3), axis=0)\n",
    "\n",
    "###  Test Data\n",
    "# Extract all 9s and 3s\n",
    "y_test_9 = y_test[y_test == 9]\n",
    "y_test_3 = y_test[y_test == 3]\n",
    "X_test_9 = X_test[y_test == 9]\n",
    "X_test_3 = X_test[y_test == 3]\n",
    "\n",
    "## Concatenate both 9 and 3\n",
    "X_test2 = np.concatenate((X_test_9, X_test_3), axis=0)\n",
    "y_test2 = np.concatenate((y_test_9, y_test_3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28) (60000,) (10000,)\n",
      "(12080, 28, 28) (2019, 28, 28) (12080,) (2019,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 9], dtype=uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape)\n",
    "np.unique(y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sahpe of training data :  (60000, 28, 28)\n",
      "label ;  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## data review and visuqlization\n",
    "print(\"Sahpe of training data : \", X_train.shape)\n",
    "i = 11\n",
    "print(\"label ; \", y_train2[i])\n",
    "plt.imshow(X_train2[i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Engineering - Normalization\n",
    "X_train3 = X_train2.astype('float32')/255.\n",
    "X_test3 = X_test2.astype('float32')/255.\n",
    "\n",
    "## Reshape from 28 by 28 to 784 for model\n",
    "X_train4 = X_train3.reshape(len(X_train3), np.prod(X_train3.shape[1:]))\n",
    "X_test4 = X_test3.reshape(len(X_test3), np.prod(X_test3.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12080, 28, 28) (2019, 28, 28)\n",
      "(12080, 784) (2019, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train3.shape, X_test3.shape)\n",
    "print(X_train4.shape, X_test4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([False,  True]), array([6131, 5949], dtype=int64))\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "True\n",
      "<class 'numpy.bool_'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prepare y variables\n",
    "y_train_binary = y_train2 == 9\n",
    "y_test_binary = y_test2 == 9\n",
    "\n",
    "print(np.unique(y_train_binary, return_counts=True))\n",
    "print(y_train_binary[:10])\n",
    "print(y_train_binary[1])\n",
    "print(type(y_train_binary[1]))\n",
    "y_train_binary[1] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Algorithms\n",
    "### Logistic Regression\n",
    "### Train Logistic Regression model with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         -4.95443393e-05, -1.10381031e-04, -5.36721418e-05,\n",
       "         -1.45506621e-06, -2.66795303e-06, -6.91798917e-03,\n",
       "         -2.70093671e-02, -2.49219251e-02, -5.74291582e-03,\n",
       "         -9.26231978e-07, -1.09685366e-07,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00, -1.24549260e-05, -3.57982277e-04,\n",
       "         -3.15586524e-04, -4.83753314e-02, -2.45668054e-01,\n",
       "         -6.74358553e-02, -1.63362410e-01, -2.56018547e-01,\n",
       "         -3.00605324e-01, -4.44957114e-01, -5.38990578e-01,\n",
       "         -7.86296380e-01, -7.56875872e-01, -5.45597185e-01,\n",
       "         -4.03912793e-01, -2.03876629e-01, -1.14003758e-01,\n",
       "         -6.91941875e-02, -3.65130171e-02,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00, -5.61545756e-08,\n",
       "         -7.48086700e-05, -8.73941604e-05, -6.59906126e-03,\n",
       "         -5.20046351e-02, -8.11432312e-02, -3.60886835e-01,\n",
       "         -4.76979399e-01, -7.26431635e-01, -1.06455644e+00,\n",
       "         -1.02416051e+00, -5.86680867e-01, -4.51563664e-01,\n",
       "         -4.21875568e-01, -6.10378897e-02, -1.17311720e+00,\n",
       "         -5.61484085e-01, -8.01475906e-01, -2.61945465e-01,\n",
       "         -1.24520691e-01, -4.80741607e-01, -2.75372650e-01,\n",
       "         -2.64740819e-03, -1.11617601e-04,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00, -4.78306842e-05, -8.99722753e-03,\n",
       "         -9.50459863e-03, -8.53825486e-02, -5.79860861e-01,\n",
       "         -9.67819564e-01, -5.22379346e-01, -9.19198613e-01,\n",
       "         -5.35933209e-02,  1.17979919e-01, -5.96525036e-01,\n",
       "          3.09922542e-01, -6.95319805e-01,  3.75518717e-01,\n",
       "         -1.15243600e+00,  4.94430467e-02,  2.70201897e-01,\n",
       "         -4.61721476e-01, -5.99956008e-01, -5.29959732e-01,\n",
       "         -5.15554859e-01, -3.76491304e-01, -1.19878407e-01,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00, -4.46163416e-03, -3.73247373e-02,\n",
       "         -4.91875035e-02, -7.78609138e-02, -5.01503275e-01,\n",
       "         -7.44554339e-01, -6.94857462e-01, -2.24980974e-01,\n",
       "          6.36829095e-02, -1.22924123e+00,  7.50020403e-01,\n",
       "          4.15996463e-01, -4.37094482e-01,  1.57036632e-01,\n",
       "         -6.56563050e-01, -1.04003475e-01,  3.32955289e-01,\n",
       "         -3.19083673e-01,  1.33729998e-01, -3.09620383e-01,\n",
       "         -3.85237259e-01, -1.32800017e-01, -3.76488466e-01,\n",
       "         -1.15351021e-01,  7.00794531e-03,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00, -2.04570089e-01,\n",
       "         -6.70659065e-02, -8.30458308e-02, -3.49714154e-01,\n",
       "         -3.36400647e-01,  5.23927179e-01, -5.69958025e-01,\n",
       "         -2.89686156e-01,  1.52823380e-02, -9.38161295e-02,\n",
       "         -2.64417208e-01, -2.71002500e-01,  2.13523980e-01,\n",
       "         -3.85071831e-01,  8.33476928e-02,  8.23659568e-01,\n",
       "         -2.20436438e-01, -9.88031286e-02, -4.09751139e-02,\n",
       "          3.90482569e-01,  2.00459145e-01,  5.44298573e-01,\n",
       "         -6.53607204e-01, -1.41404304e-01,  7.37040747e-02,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         -2.24874408e-02, -5.96851310e-02, -3.10786610e-01,\n",
       "         -4.61096519e-01,  5.82149682e-01,  9.00035870e-02,\n",
       "         -1.13785613e+00,  9.00479646e-01,  7.31543076e-02,\n",
       "          1.25227917e-02,  1.09408538e-01, -1.00985791e+00,\n",
       "         -3.09149952e-01,  1.52728325e-01, -8.38205082e-02,\n",
       "         -3.61871961e-01, -7.62110533e-01,  4.39265676e-01,\n",
       "         -1.84853225e-01, -4.98458049e-01, -4.28549425e-02,\n",
       "         -8.36390187e-01, -1.33283855e-01, -1.73501956e-01,\n",
       "          5.57178743e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00, -1.62854610e-02, -3.39594043e-02,\n",
       "         -3.64539562e-01, -5.44013091e-01,  3.00541476e-01,\n",
       "          3.53985742e-01,  1.85915767e-01, -1.60884832e-01,\n",
       "         -2.37678197e-01,  3.52381927e-01,  7.26416954e-01,\n",
       "         -9.05607988e-03, -1.47673785e-01, -1.06729774e-01,\n",
       "          1.38451706e-02, -1.78454427e-01, -8.51018808e-04,\n",
       "          1.23986841e-01, -4.27309287e-01, -2.17725841e-03,\n",
       "         -1.89631494e-01, -7.39201351e-01, -5.44321592e-01,\n",
       "         -7.28313975e-02, -5.48178219e-03,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00, -8.10413936e-03,\n",
       "         -2.15594332e-02, -4.62064711e-01, -8.86758411e-02,\n",
       "          4.21424966e-01,  4.21517975e-01,  2.44799220e-01,\n",
       "          5.21017719e-01,  3.83269851e-01,  7.51885870e-01,\n",
       "          4.66906342e-01,  7.41317082e-01, -1.37254011e+00,\n",
       "         -1.40055233e-01,  5.33479004e-01,  7.96196256e-02,\n",
       "          8.78205361e-02, -1.44969629e-01,  3.82615274e-01,\n",
       "         -8.02977443e-01,  5.94755350e-01, -4.49450426e-01,\n",
       "         -6.41764331e-01,  7.10077234e-02, -4.01485361e-02,\n",
       "          8.08088312e-06,  0.00000000e+00,  0.00000000e+00,\n",
       "         -5.94303569e-03, -3.94617820e-02, -1.11726017e-01,\n",
       "         -4.15716405e-01,  3.56584324e-01,  2.84435158e-01,\n",
       "          7.98039146e-01,  8.21268190e-01,  7.56524830e-01,\n",
       "          1.66598397e+00,  9.40140204e-01,  1.16295598e+00,\n",
       "         -3.93035506e-01, -3.88301309e-01,  8.52163298e-02,\n",
       "          8.46058772e-01,  7.95298429e-01,  8.54375566e-01,\n",
       "          4.11352864e-01,  1.05618081e+00,  5.89336414e-01,\n",
       "          4.64904094e-01,  2.81741841e-01,  2.08234347e-01,\n",
       "         -3.77162404e-03,  1.81207680e-05,  0.00000000e+00,\n",
       "          0.00000000e+00, -1.00336964e-03, -2.13055412e-04,\n",
       "          2.29196646e-01,  2.15725469e-01,  6.85691368e-01,\n",
       "          8.19210610e-01,  3.07457400e-01,  9.95095083e-01,\n",
       "          1.84926527e-01, -5.98848964e-01,  5.44608001e-01,\n",
       "          1.60853971e-01, -3.06051739e-01, -4.69650875e-01,\n",
       "         -3.60262580e-01,  1.75775100e-01, -4.48620361e-01,\n",
       "          2.14488939e-02,  2.66120077e-01, -1.79336862e-01,\n",
       "          8.25682618e-01,  1.44672536e+00,  7.22373103e-01,\n",
       "          2.20369959e-01, -2.80570634e-02,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          5.06942440e-05, -1.05292197e-02,  3.03674173e-01,\n",
       "         -1.57511219e-02, -1.91534191e-01,  6.13122882e-01,\n",
       "          1.37493966e-01,  9.09137343e-01,  1.22230411e+00,\n",
       "          5.77198541e-01, -1.36536633e-01, -4.25087498e-01,\n",
       "         -3.68637087e-01,  2.49737023e-01,  5.97895579e-01,\n",
       "          6.22782117e-01, -1.73718292e-01,  3.52936557e-01,\n",
       "          9.88615799e-01,  6.40824309e-01,  1.60770079e+00,\n",
       "          8.74844771e-01,  9.79489813e-02, -1.49628696e-03,\n",
       "          1.01723513e-05,  0.00000000e+00,  0.00000000e+00,\n",
       "         -5.96044775e-04, -1.63836937e-05, -1.23095871e-01,\n",
       "          5.02962204e-01,  8.02430762e-01,  1.23115547e+00,\n",
       "          8.22964777e-01,  1.68204286e-01,  5.25544922e-02,\n",
       "          9.99586779e-02,  1.41619028e-02, -1.86781617e-01,\n",
       "          1.19906085e-01, -4.12800330e-01, -5.25993151e-01,\n",
       "          1.00376677e+00,  4.62269553e-01,  4.39197493e-01,\n",
       "          5.84167646e-01,  1.54614032e-01,  1.76462848e-01,\n",
       "          1.44770472e+00,  3.55748062e-01, -7.90307081e-02,\n",
       "         -5.55636540e-04,  1.21285726e-05,  0.00000000e+00,\n",
       "          0.00000000e+00, -6.95833552e-05, -2.18510023e-02,\n",
       "          3.07851004e-01,  6.55582608e-01,  4.63138195e-01,\n",
       "          7.85197650e-01,  5.72369255e-01,  2.97282156e-01,\n",
       "          6.09748975e-01,  7.64565559e-01,  3.98131762e-02,\n",
       "         -1.78920830e-01, -1.44401061e-01, -6.14785647e-02,\n",
       "          2.91745949e-02,  2.11007057e-01,  6.35278407e-02,\n",
       "          2.71498255e-02,  1.21282551e-01, -2.18059288e-01,\n",
       "          3.26500378e-01,  2.37261678e-01, -2.99035845e-02,\n",
       "         -5.22997957e-01,  4.31989343e-05, -3.32279808e-03,\n",
       "          0.00000000e+00,  0.00000000e+00, -1.04019360e-04,\n",
       "         -3.29533046e-01, -5.80482118e-02,  4.00725774e-01,\n",
       "          5.02251870e-01,  4.72206420e-01, -5.15857165e-03,\n",
       "          4.08083196e-02, -3.10223162e-01, -2.40405575e-01,\n",
       "         -3.71275479e-01, -3.99944107e-01, -6.20498308e-01,\n",
       "         -1.92293311e-01,  3.45272671e-01,  7.83460963e-01,\n",
       "          5.33955730e-01, -5.58760817e-02, -7.79996841e-02,\n",
       "          6.79646110e-02, -5.36964994e-01,  9.19887882e-03,\n",
       "         -2.77068154e-01, -8.87024559e-01,  3.67929436e-05,\n",
       "         -2.34909154e-07,  0.00000000e+00,  0.00000000e+00,\n",
       "         -6.83595468e-04, -3.92296111e-01, -4.93976842e-01,\n",
       "         -5.67414399e-01,  2.10636286e-01, -1.38465988e-01,\n",
       "         -7.97645258e-01,  7.87253032e-01,  8.01872375e-01,\n",
       "          1.07671361e-01, -4.07837660e-01, -3.64864566e-01,\n",
       "         -6.92413597e-02,  4.37265411e-01,  4.13116050e-01,\n",
       "          1.84258066e-01, -8.48061017e-01,  7.58602965e-02,\n",
       "         -8.90858145e-01,  2.72260970e-01, -1.45229059e+00,\n",
       "         -1.07535359e+00, -1.30101601e+00, -4.46396517e-01,\n",
       "          8.51279497e-04,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.36566952e-04, -2.69802785e-04, -1.08158523e-01,\n",
       "         -6.49061581e-01, -1.53154012e+00, -7.98715824e-01,\n",
       "          1.50831499e-01,  1.39857035e-01, -3.05540068e-02,\n",
       "         -4.13922982e-01, -3.12460415e-01, -2.20722041e-01,\n",
       "         -3.91893460e-01, -2.17309397e-01,  1.07232257e+00,\n",
       "         -8.98516813e-01, -4.24007000e-01,  4.36336190e-01,\n",
       "         -5.74464327e-01, -5.61938271e-01, -3.85657020e-01,\n",
       "         -5.51411703e-01, -1.14575622e+00, -1.26784760e+00,\n",
       "         -1.64185069e-01,  1.16978230e-03,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00, -1.75500346e-04,\n",
       "         -1.90668681e-01, -6.41823560e-01, -1.39614190e+00,\n",
       "         -6.99731534e-01, -7.35404184e-02,  5.29899934e-01,\n",
       "         -6.75409606e-01, -5.95260541e-01,  1.19387079e-01,\n",
       "          5.12307137e-03,  6.64095336e-01,  2.86650644e-02,\n",
       "         -2.39156188e-01, -1.27322820e-01, -8.16810580e-01,\n",
       "         -1.38020972e+00, -1.94627239e-01, -4.75430784e-01,\n",
       "         -6.48595862e-01, -1.19916450e+00, -7.68675566e-01,\n",
       "         -8.01476339e-01,  8.48467430e-02,  2.07839989e-03,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         -1.02683197e-04, -2.12209144e-01, -9.12445284e-01,\n",
       "         -1.47552080e+00,  6.09212256e-01, -1.88255821e-03,\n",
       "         -8.23974221e-01, -8.66470119e-01, -5.89288842e-01,\n",
       "          1.92105088e-01,  1.43567531e-01,  3.91667343e-01,\n",
       "         -6.58692311e-01, -3.38365140e-01,  1.43781764e-01,\n",
       "         -3.79981478e-01, -4.82672225e-01, -1.04302565e+00,\n",
       "         -8.33176777e-01, -7.57768048e-01, -1.38066542e+00,\n",
       "         -7.34817486e-01, -1.29405688e+00,  4.57637914e-01,\n",
       "          1.05701363e-02, -5.59544584e-05,  0.00000000e+00,\n",
       "          0.00000000e+00, -7.16095266e-04, -2.12416697e-01,\n",
       "         -5.82360270e-01, -1.31722959e+00,  2.31679069e-02,\n",
       "         -1.58170871e-01, -1.36794491e+00, -6.77922034e-02,\n",
       "          1.75363903e-01, -7.26080617e-02, -4.15153579e-01,\n",
       "          1.75675872e-02,  2.37135421e-01, -1.04259726e+00,\n",
       "         -7.91270126e-01, -1.20327631e-01, -1.44572126e-01,\n",
       "         -3.99570616e-01, -5.94054267e-01, -3.61905390e-01,\n",
       "         -4.39986442e-01, -4.29644050e-01,  1.28599431e-01,\n",
       "          5.23819914e-01,  3.17065470e-03, -2.36730405e-05,\n",
       "          0.00000000e+00,  0.00000000e+00, -2.55056403e-06,\n",
       "         -1.08997116e-01, -3.09331373e-01, -3.72913547e-01,\n",
       "         -4.05082587e-01, -1.49767586e-01, -9.03916440e-02,\n",
       "          9.10022998e-01, -4.53702394e-01,  2.87036628e-01,\n",
       "         -3.66919472e-01, -3.33275104e-02,  5.47790878e-01,\n",
       "          2.19778229e-01, -3.57641762e-01,  4.07063374e-02,\n",
       "         -2.00345490e-01,  5.01700416e-01, -3.58429989e-01,\n",
       "         -6.71483938e-01,  2.69389701e-01,  1.00692390e-03,\n",
       "          3.44665066e-01,  3.48104226e-01,  3.37349339e-03,\n",
       "         -1.47630536e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00, -2.59027867e-01, -4.14802711e-01,\n",
       "         -1.20828541e+00, -4.54576032e-01, -1.03004604e+00,\n",
       "         -5.78575276e-01, -1.49638706e-01, -2.19237756e-01,\n",
       "         -3.89345091e-01, -1.04272912e+00,  5.85145610e-01,\n",
       "         -2.87571044e-01,  7.12584136e-01,  1.04213052e-01,\n",
       "          1.43137250e-01,  2.40135539e-02,  7.34852893e-02,\n",
       "          2.09182284e-01,  3.34611614e-01,  1.01635601e+00,\n",
       "          6.43366934e-01,  7.54107812e-01,  1.61079922e-01,\n",
       "         -1.50862351e-03, -2.39161467e-02,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00, -4.49418929e-02,\n",
       "         -2.12791181e-01, -2.92816184e-01,  3.03371222e-01,\n",
       "         -4.84724348e-01,  3.57066177e-02, -3.50100078e-02,\n",
       "         -8.02599545e-01,  4.42393149e-01, -2.25642943e-01,\n",
       "         -6.84212326e-01, -5.08547547e-01, -7.05938791e-01,\n",
       "         -3.82804335e-01, -4.22436440e-01, -1.77922148e-01,\n",
       "         -2.64253779e-01,  6.02036489e-01,  2.33243628e-01,\n",
       "          2.29987707e-01,  1.20726715e+00,  7.13572166e-01,\n",
       "          9.12266508e-02,  1.06221459e-03,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.71825856e-04, -1.64396253e-03,  4.80643077e-01,\n",
       "          1.98892832e-01, -3.82196213e-01, -7.92198540e-01,\n",
       "         -8.14859486e-01, -6.18919019e-01, -5.55594122e-01,\n",
       "         -1.97435418e-01, -1.04448360e+00, -2.97917229e-03,\n",
       "          2.01738234e-01,  4.92895669e-01, -2.39869791e-01,\n",
       "          7.81611539e-02,  2.08849579e-01, -2.19049558e-02,\n",
       "          7.10771360e-01,  5.72342878e-01,  2.95307871e-01,\n",
       "          5.64055018e-02,  7.40880680e-03,  5.59612654e-04,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  1.16851283e-03,\n",
       "          9.79597692e-03, -1.33732256e-01, -2.58730929e-01,\n",
       "         -2.55057714e-01, -1.96572080e-01,  2.77232553e-02,\n",
       "         -5.86476999e-01, -4.87571989e-01,  9.61855548e-02,\n",
       "          1.47728514e-01, -3.97347566e-02, -1.24042093e-01,\n",
       "         -7.85567826e-02, -2.17741195e-01, -1.36234534e-01,\n",
       "         -2.42872832e-01,  3.48690159e-01,  4.19616258e-01,\n",
       "          2.77185983e-01,  3.62192401e-03,  7.65905858e-07,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.22234746e-03,  6.94651096e-03,  6.38319382e-03,\n",
       "          2.04427509e-03,  9.91250866e-04,  1.32536056e-03,\n",
       "          1.13516825e-02,  2.34565610e-03,  6.20519969e-03,\n",
       "          2.86418031e-03,  2.87716094e-03,  3.75832114e-03,\n",
       "          5.38390366e-02,  2.60394015e-02,  1.54568893e-01,\n",
       "          1.05399053e-01,  2.70019585e-02,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00]]), array([1.33197633]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Logistic Regression as model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "## Train the model\n",
    "log_reg.fit(X_train4, y_train_binary)\n",
    "log_reg.coef_, log_reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the trained logistic regression model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kevin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kevin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.97181009, 0.96879643, 0.98214286])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Validate the accuracy\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(log_reg, X_test4, y_test_binary, cv=3, scoring=\"accuracy\")  ### three folding validataion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=inf, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pick up SVM Classifier model\n",
    "svm_clf = SVC(kernel=\"linear\", C=float(\"inf\"))\n",
    "\n",
    "## Train the model\n",
    "svm_clf.fit(X_train4, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97181009, 0.96879643, 0.97916667])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Validate the accuracy\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(svm_clf, X_test4, y_test_binary, cv=3, scoring=\"accuracy\")  ### three folding validataion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=X_train4.shape[1], activation='relu'))\n",
    "#model.add(Dropout(0.75))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "#model.add(Dropout(0.75))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "#model.add(Dropout(0.75))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 84,591\n",
      "Trainable params: 84,591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up Callbacks\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11959 samples, validate on 121 samples\n",
      "Epoch 1/50\n",
      "11959/11959 [==============================] - 0s 38us/step - loss: 0.2569 - binary_accuracy: 0.9336 - val_loss: 0.0534 - val_binary_accuracy: 0.9917\n",
      "Epoch 2/50\n",
      "11959/11959 [==============================] - 0s 13us/step - loss: 0.0671 - binary_accuracy: 0.9776 - val_loss: 0.0621 - val_binary_accuracy: 0.9917\n",
      "Epoch 3/50\n",
      "11959/11959 [==============================] - 0s 13us/step - loss: 0.0446 - binary_accuracy: 0.9864 - val_loss: 0.0604 - val_binary_accuracy: 0.9917\n",
      "Epoch 4/50\n",
      "11959/11959 [==============================] - 0s 13us/step - loss: 0.0344 - binary_accuracy: 0.9895 - val_loss: 0.0510 - val_binary_accuracy: 0.9917\n",
      "Epoch 5/50\n",
      "11959/11959 [==============================] - 0s 12us/step - loss: 0.0277 - binary_accuracy: 0.9921 - val_loss: 0.0415 - val_binary_accuracy: 0.9917\n",
      "Epoch 6/50\n",
      "11959/11959 [==============================] - 0s 12us/step - loss: 0.0227 - binary_accuracy: 0.9926 - val_loss: 0.0294 - val_binary_accuracy: 0.9917\n",
      "Epoch 7/50\n",
      "11959/11959 [==============================] - 0s 14us/step - loss: 0.0182 - binary_accuracy: 0.9939 - val_loss: 0.0266 - val_binary_accuracy: 0.9917\n",
      "Epoch 8/50\n",
      "11959/11959 [==============================] - 0s 13us/step - loss: 0.0149 - binary_accuracy: 0.9960 - val_loss: 0.0331 - val_binary_accuracy: 0.9917\n",
      "Epoch 9/50\n",
      "11959/11959 [==============================] - 0s 12us/step - loss: 0.0118 - binary_accuracy: 0.9968 - val_loss: 0.0220 - val_binary_accuracy: 0.9917\n",
      "Epoch 10/50\n",
      "11959/11959 [==============================] - 0s 12us/step - loss: 0.0086 - binary_accuracy: 0.9977 - val_loss: 0.0190 - val_binary_accuracy: 0.9917\n",
      "Epoch 11/50\n",
      "11959/11959 [==============================] - 0s 13us/step - loss: 0.0071 - binary_accuracy: 0.9982 - val_loss: 0.0191 - val_binary_accuracy: 0.9917\n",
      "Epoch 12/50\n",
      "11959/11959 [==============================] - 0s 13us/step - loss: 0.0060 - binary_accuracy: 0.9986 - val_loss: 0.0132 - val_binary_accuracy: 0.9917\n",
      "Epoch 13/50\n",
      "11959/11959 [==============================] - 0s 14us/step - loss: 0.0044 - binary_accuracy: 0.9994 - val_loss: 0.0188 - val_binary_accuracy: 0.9917\n",
      "Epoch 14/50\n",
      "11959/11959 [==============================] - 0s 13us/step - loss: 0.0038 - binary_accuracy: 0.9992 - val_loss: 0.0090 - val_binary_accuracy: 0.9917\n",
      "Epoch 15/50\n",
      "11959/11959 [==============================] - 0s 13us/step - loss: 0.0036 - binary_accuracy: 0.9993 - val_loss: 0.0143 - val_binary_accuracy: 0.9917\n",
      "Epoch 16/50\n",
      "11959/11959 [==============================] - 0s 13us/step - loss: 0.0024 - binary_accuracy: 0.9997 - val_loss: 0.0169 - val_binary_accuracy: 0.9917\n",
      "Epoch 17/50\n",
      "11959/11959 [==============================] - 0s 13us/step - loss: 0.0020 - binary_accuracy: 0.9997 - val_loss: 0.0235 - val_binary_accuracy: 0.9917\n",
      "Epoch 18/50\n",
      "11959/11959 [==============================] - 0s 12us/step - loss: 0.0018 - binary_accuracy: 0.9998 - val_loss: 0.0070 - val_binary_accuracy: 0.9917\n",
      "Epoch 19/50\n",
      "11959/11959 [==============================] - 0s 12us/step - loss: 0.0018 - binary_accuracy: 0.9997 - val_loss: 0.0205 - val_binary_accuracy: 0.9917\n",
      "Epoch 20/50\n",
      "11959/11959 [==============================] - 0s 13us/step - loss: 9.5961e-04 - binary_accuracy: 0.9999 - val_loss: 0.0229 - val_binary_accuracy: 0.9917\n",
      "Epoch 21/50\n",
      "11959/11959 [==============================] - 0s 13us/step - loss: 6.6260e-04 - binary_accuracy: 1.0000 - val_loss: 0.0187 - val_binary_accuracy: 0.9917\n",
      "Epoch 22/50\n",
      "11959/11959 [==============================] - 0s 14us/step - loss: 5.3818e-04 - binary_accuracy: 1.0000 - val_loss: 0.0296 - val_binary_accuracy: 0.9917\n",
      "Epoch 23/50\n",
      "11959/11959 [==============================] - 0s 13us/step - loss: 5.9439e-04 - binary_accuracy: 1.0000 - val_loss: 0.0233 - val_binary_accuracy: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f6192237f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Model 1\n",
    "## Train the model with equal weight on True/False label\n",
    "n_epochs = 50\n",
    "batch_size = 512\n",
    "validation_split = 0.01\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(X_train4, y_train_binary, epochs=n_epochs, batch_size=batch_size, shuffle=True, \n",
    "          validation_split=validation_split, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.028638617982140017\n",
      "Test accuracy: 0.9930658741951461\n"
     ]
    }
   ],
   "source": [
    "## Evaludation socre\n",
    "score = model.evaluate(X_test4, y_test_binary, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
